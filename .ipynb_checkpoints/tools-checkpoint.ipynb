{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ChrisBagdon/Citation_Classification/blob/main/tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xpJHlwHakRy5"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCQhwgzRiA5C"
   },
   "outputs": [],
   "source": [
    "text = \"By clustering with lowly aggressive close kin (King 1989a,b; Viblanc et al. 2010; Arnaud, Dobson & Murie 2012), breeding females may decrease the time/energy cost of maintaining territorial boundaries (Festa-Bianchet & Boag 1982; Murie & Harris 1988), which could ultimately lead to increases in net energy income (TA) or higher allocations in somatic or reproductive functions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NBobkWpckjCT"
   },
   "outputs": [],
   "source": [
    "tokens = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CX6pYen8ifHG"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, tokens):\n",
    "  cur_token =\"\"\n",
    "  for char in text:\n",
    "    # Check if is apart of token\n",
    "    if char.isalnum() or char == \"'\":\n",
    "      cur_token += char\n",
    "      continue\n",
    "    # Check for space\n",
    "    elif char == \" \":\n",
    "      if len(cur_token) > 0:\n",
    "        if cur_token in tokens:\n",
    "          tokens[cur_token] += 1\n",
    "          cur_token = \"\"\n",
    "          continue\n",
    "        else:\n",
    "          tokens[cur_token] = 1\n",
    "          cur_token = \"\"\n",
    "          continue\n",
    "    # Check if punctuation\n",
    "    else:\n",
    "      if len(cur_token) > 0:\n",
    "        if cur_token in tokens:\n",
    "          tokens[cur_token] += 1\n",
    "          cur_token = \"\"\n",
    "        else:\n",
    "          tokens[cur_token] = 1\n",
    "          cur_token = \"\"\n",
    "      if char in tokens:\n",
    "        tokens[char] += 1\n",
    "        continue\n",
    "      else:\n",
    "        tokens[char] = 1\n",
    "        continue\n",
    "  if len(cur_token) > 0:\n",
    "    if cur_token in tokens:\n",
    "          tokens[cur_token] += 1\n",
    "          cur_token = \"\"\n",
    "    else:\n",
    "      tokens[cur_token] = 1\n",
    "      cur_token = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "pVmzIP3xnDoi",
    "outputId": "27f46cc2-46d2-424c-cd48-eaabd403d6ef"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3493f14af57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "tokenize(text, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aQFDG0ynLDv"
   },
   "outputs": [],
   "source": [
    "text_2 = \"Ophthalmic symptoms are rare manifestations of the intracranial arachnoid cyst, and include unilateral exophthalmos, visual field abnormality, decreased visual acuity and isolated palsies of the third, fourth and sixth cranial nerves [1–5].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTIqlyUPncnT"
   },
   "outputs": [],
   "source": [
    "tokenize(text_2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uClSzDMulpqk",
    "outputId": "df4fb6c7-835e-46d5-fca4-de644897cc77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('By', 1), ('clustering', 1), ('with', 1), ('lowly', 1), ('aggressive', 1), ('close', 1), ('kin', 1), ('(', 3), ('King', 1), ('1989a', 1), (',', 8), ('b', 1), (';', 3), ('Viblanc', 1), ('et', 1), ('al', 1), ('.', 3), ('2010', 1), ('Arnaud', 1), ('Dobson', 1), ('&', 3), ('Murie', 2), ('2012', 1), (')', 3), ('breeding', 1), ('females', 1), ('may', 1), ('decrease', 1), ('the', 3), ('time', 1), ('/', 1), ('energy', 2), ('cost', 1), ('of', 3), ('maintaining', 1), ('territorial', 1), ('boundaries', 1), ('Festa', 1), ('-', 1), ('Bianchet', 1), ('Boag', 1), ('1982', 1), ('Harris', 1), ('1988', 1), ('which', 1), ('could', 1), ('ultimately', 1), ('lead', 1), ('to', 1), ('increases', 1), ('in', 2), ('net', 1), ('income', 1), ('TA', 1), ('or', 2), ('higher', 1), ('allocations', 1), ('somatic', 1), ('reproductive', 1), ('functions', 1), ('Ophthalmic', 1), ('symptoms', 1), ('are', 1), ('rare', 1), ('manifestations', 1), ('intracranial', 1), ('arachnoid', 1), ('cyst', 1), ('and', 3), ('include', 1), ('unilateral', 1), ('exophthalmos', 1), ('visual', 2), ('field', 1), ('abnormality', 1), ('decreased', 1), ('acuity', 1), ('isolated', 1), ('palsies', 1), ('third', 1), ('fourth', 1), ('sixth', 1), ('cranial', 1), ('nerves', 1), ('[', 1), ('1', 1), ('–', 1), ('5', 1), (']', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tokens.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "QATbs-Sf5uEd"
   },
   "outputs": [],
   "source": [
    "class naive_bayes:\n",
    "  def __init__(self):\n",
    "      self.labels = {}\n",
    "      self.doc_count = 0\n",
    "      self.bin_size = 0\n",
    "  \n",
    "  def train(self, X, Y):\n",
    "    for string, label in zip(X, Y):\n",
    "      # Count instances of labels\n",
    "      if label not in self.labels:\n",
    "        self.labels[label] = {'count':1, 'terms':{}}\n",
    "      else:\n",
    "        self.labels[label]['count'] += 1\n",
    "      # Count tokens from document\n",
    "      tokenize(string, self.labels[label]['terms'])\n",
    "      # Increase total document count\n",
    "      self.doc_count += 1\n",
    "    \n",
    "    # Tally bin_size for smoothing\n",
    "    terms_list = []\n",
    "    for label, labels_dic in self.labels.items():\n",
    "      terms_list = terms_list + list(labels_dic['terms'].keys())\n",
    "    self.bin_size += len(set(terms_list))\n",
    "    # Calculate class statistics\n",
    "    for label, labels_dic in self.labels.items():\n",
    "      # Calculate label prior probability\n",
    "      self.labels[label][\"prior\"] = labels_dic['count'] / self.doc_count\n",
    "      # Save total number of tokens in label + smoothing\n",
    "      self.labels[label][\"term_count\"] = sum(labels_dic['terms'].values())+self.bin_size\n",
    "      # Calculate probability of each token in label + smoothing\n",
    "      terms = labels_dic['terms'].keys()\n",
    "      #for term in terms:\n",
    "        #print((labels_dic['terms'][term]+1) / labels_dic[\"term_count\"])\n",
    "      self.labels[label][\"term_probs\"] = {term:(labels_dic['terms'][term]+1) /\n",
    "                                          labels_dic[\"term_count\"]\n",
    "                                           for term in terms}\n",
    "\n",
    "  def predict(self, X, use_log=True):\n",
    "    predictions = []\n",
    "\n",
    "    for string in X:\n",
    "      tokens = {}\n",
    "      tokenize(string, tokens)\n",
    "      probabilities = []\n",
    "      for label, label_dic in self.labels.items():\n",
    "        if use_log:\n",
    "          prob = sum(log(label_dic[\"term_probs\"][token])*count \n",
    "                        if token in label_dic['terms']\n",
    "                        else log(1/label_dic['term_count'])*count \n",
    "                        for token, count in tokens.items()) \\\n",
    "                  + log(label_dic['prior'])\n",
    "        else:\n",
    "          prob = label_dic['prior']\n",
    "          for token, count in tokens.items():\n",
    "            if token in label_dic['terms'].keys():\n",
    "              prob = prob*(label_dic[\"term_probs\"][token]**count)\n",
    "            else:\n",
    "              prob = prob*((1/label_dic['term_count'])**count)\n",
    "              #print(prob)\n",
    "        probabilities.append((label, prob))\n",
    "      predictions.append(max(probabilities, key=lambda item:item[1])[0])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "3URnBWLHoliU"
   },
   "outputs": [],
   "source": [
    "X_train = ['Red Blue Blue',\n",
    "         'Blue Blue Green',\n",
    "         'Blue Yellow',\n",
    "         'Big Small Blue']\n",
    "Y_train = ['color', 'color', 'color', 'size']\n",
    "X_test = ['Blue Blue Blue Big Small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "R0v5bk_INOcB"
   },
   "outputs": [],
   "source": [
    "model = naive_bayes()\n",
    "model.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "PyVzU9RPNsur"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCXBMtR5N1pb",
    "outputId": "de3e7fe9-bc8f-4d41-98ea-482c6f795ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('color', -8.10769031284391)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hm_ZEYeWOJYH",
    "outputId": "d0ae4e28-1b69-4c1c-f007-09a8d0b8374a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': {'count': 3,\n",
       "  'prior': 0.75,\n",
       "  'term_count': 14,\n",
       "  'term_probs': {'Blue': 0.42857142857142855,\n",
       "   'Green': 0.14285714285714285,\n",
       "   'Red': 0.14285714285714285,\n",
       "   'Yellow': 0.14285714285714285},\n",
       "  'terms': {'Blue': 5, 'Green': 1, 'Red': 1, 'Yellow': 1}},\n",
       " 'size': {'count': 1,\n",
       "  'prior': 0.25,\n",
       "  'term_count': 9,\n",
       "  'term_probs': {'Big': 0.2222222222222222,\n",
       "   'Blue': 0.2222222222222222,\n",
       "   'Small': 0.2222222222222222},\n",
       "  'terms': {'Big': 1, 'Blue': 1, 'Small': 1}}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SK333mtOYBFr",
    "outputId": "800a2720-8f3a-445c-9e29-c085b461207d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "RsTXI5zLS6rW"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('drive/MyDrive/train.tsv') as train_file:\n",
    "  train_data = csv.reader(train_file, delimiter=\"\\t\")\n",
    "  X_train, Y_train = [],[]\n",
    "  for row in train_data:\n",
    "    X_train.append(row[2])\n",
    "    Y_train.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-HGK1liTNPg"
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNq5cr1Fn-WT"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "9onAR7-qpXGs"
   },
   "outputs": [],
   "source": [
    "with open('drive/MyDrive/dev.tsv') as dev_file:\n",
    "  dev_data = csv.reader(dev_file, delimiter=\"\\t\")\n",
    "  X_dev, Y_dev = [],[]\n",
    "  for row in dev_data:\n",
    "    X_dev.append(row[2])\n",
    "    Y_dev.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "6xhn2L38p1rY"
   },
   "outputs": [],
   "source": [
    "model = naive_bayes()\n",
    "model.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CIdPSxNp_yF"
   },
   "outputs": [],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "4NZy00Hmshb2"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "TVssYMOHswAn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def evaluate(predictions, gold_standard):\n",
    "    # Collect all unique labels from predictions and gold_std\n",
    "    labels_set = set(predictions + gold_standard)\n",
    "    labels = {}\n",
    "    for i, label in enumerate(labels_set):\n",
    "        labels[label] = i\n",
    "    # Create confusion matrix\n",
    "    confusion_matrix = np.zeros((len(labels_set),len(labels_set)))\n",
    "    for pred, gold in zip(predictions, gold_standard):\n",
    "        confusion_matrix[labels[pred]][labels[gold]] += 1\n",
    "    labels_index = list(labels_set); labels_index.append('overall')\n",
    "    columns = []\n",
    "    # Create scores table\n",
    "    scores = pd.DataFrame(np.zeros((len(labels_set), 3)))\n",
    "    scores.columns = ['Precision', 'Recall', 'F1']\n",
    "    overall_TP = 0\n",
    "    # Calculate P, R, F1 and populate scores table\n",
    "    for label in labels_set:\n",
    "        i = labels[label]\n",
    "        # Possible error case (Precision): denominator == 0; divide by 0\n",
    "        if np.sum(confusion_matrix, axis=0)[i] == 0:\n",
    "            scores['Precision'][i] = 0\n",
    "        else:\n",
    "            scores['Precision'][i] = confusion_matrix[i][i] / np.sum(confusion_matrix, axis=0)[i]\n",
    "        # Possible error case (Recall): denominator == 0; divide by 0\n",
    "        if np.sum(confusion_matrix, axis=1)[i] == 0:\n",
    "            scores['Recall'][i] = 0\n",
    "        else:\n",
    "            scores['Recall'][i] = confusion_matrix[i][i] / np.sum(confusion_matrix, axis=1)[i]\n",
    "        # Possible error case: P == 0 == R; divide by 0\n",
    "        if scores['Precision'][i] == 0 and scores['Recall'][i] == 0:\n",
    "            scores['F1'][i] = 0\n",
    "        else:\n",
    "            scores['F1'][i] = 2 * (scores['Precision'][i]*scores['Recall'][i]/(scores['Precision'][i]+scores['Recall'][i]))\n",
    "        overall_TP += confusion_matrix[i][i]\n",
    "    scores.loc[len(labels_set)] = [overall_TP / np.sum(confusion_matrix)] * 3\n",
    "    scores.index = labels_index\n",
    "    return (confusion_matrix, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "V9KVaq6dtHH5"
   },
   "outputs": [],
   "source": [
    "cf, scores = evaluate(predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3fZQhAytqua",
    "outputId": "a3d5d20f-8565-4bec-f1d1-ad9c66335330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Precision    Recall        F1\n",
      "result       0.560976  0.821429  0.666667\n",
      "method       0.725490  0.740000  0.732673\n",
      "background   0.871747  0.805842  0.837500\n",
      "overall      0.789301  0.789301  0.789301\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXcl0rYpArckwyFynnDr7G",
   "include_colab_link": true,
   "mount_file_id": "12j6JjWwGraOFs004ttkgRLv9ERLGgahg",
   "name": "tools.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
